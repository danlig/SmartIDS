{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impostazioni globali\n",
    "# --------------------------\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "NSL_DATASET = False\n",
    "BINARY = False\n",
    "XGB = True\n",
    "KFOLD_TRAINING = False\n",
    "KFOLDSTRAT_TRAINING = True\n",
    "GRID_SEARCH = False\n",
    "\n",
    "models = [\n",
    "    GaussianNB(),\n",
    "    LogisticRegression(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    RandomForestClassifier(),\n",
    "    MLPClassifier(hidden_layer_sizes=(20, 20), activation=\"relu\", solver=\"adam\", random_state=42)\n",
    "    ]\n",
    "PARAM_GRID = {\n",
    "    'hidden_layer_sizes': [(20,), (50,), (20, 20), (50, 20), (50, 50)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "}\n",
    "# --------------------------\n",
    "if NSL_DATASET:\n",
    "    DATASET_PATH = \"./datasets/nslkdd/\"\n",
    "\n",
    "    binary_mapping = {\n",
    "        \"normal\": \"BENIGN\"\n",
    "    }\n",
    "    multiclass_mapping = {\n",
    "        \"normal\": \"BENIGN\",\n",
    "        \"R2L\": [\"warezclient\", \"guess_passwd\", \"ftp_write\", \"multihop\", \"imap\", \"phf\", \"spy\", \"warezmaster\"],\n",
    "        \"DoS\":[\"neptune\", \"teardrop\", \"smurf\", \"pod\", \"back\", \"land\"],\n",
    "        \"U2R\":[\"rootkit\", \"buffer_overflow\", \"loadmodule\", \"perl\"],\n",
    "        \"Probe\":[\"ipsweep\", \"portsweep\", \"nmap\", \"satan\"]\n",
    "    }\n",
    "\n",
    "    Y_LABEL = \"attack\"\n",
    "else: # CICIDS\n",
    "    DATASET_PATH = \"./datasets/cicids2017/\"\n",
    "\n",
    "    binary_mapping = {\n",
    "        \"BENIGN\": \"BENIGN\"\n",
    "    }\n",
    "    multiclass_mapping = {\n",
    "        \"BENIGN\": \"BENIGN\",\n",
    "        \"Brute Force\": [\"FTP-Patator\", \"SSH-Patator\"],\n",
    "        \"DoS\":[\"DoS slowloris\", \"DoS Slowhttptest\", \"DoS Hulk\", \"DoS GoldenEye\", \"Heartbleed\"],\n",
    "        \"Web Attack\":[\"Web Attack � Brute Force\", \"Web Attack � XSS\", \"Web Attack � Sql Injection\"],\n",
    "        \"Infiltration\":\"Infiltration\",\n",
    "        \"DDoS\":\"DDoS\",\n",
    "        \"PortScan\":\"PortScan\",\n",
    "        \"Bot\":\"Bot\"\n",
    "    }\n",
    "    \n",
    "    Y_LABEL = \"Label\" \n",
    "\n",
    "if BINARY:\n",
    "    MAPPING = binary_mapping\n",
    "else:\n",
    "    MAPPING = multiclass_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import del dataset\n",
    "# --------------------------\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def dataset_import(dataset_path, verbose=True):\n",
    "    \"\"\"\n",
    "    Importa il dataset presente nella cartella specificata\n",
    "    concatenando tutti i file in un unico data frame.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ottieni tutti i file presenti nella cartella del dataset\n",
    "    file_names = os.listdir(dataset_path)\n",
    "\n",
    "    # Leggi i file e salva i dataframe in una lista\n",
    "    data_frames = []\n",
    "    for file_name in file_names:\n",
    "        file_path = os.path.join(dataset_path, file_name)\n",
    "        df = pd.read_csv(file_path)\n",
    "        data_frames.append(df)\n",
    "\n",
    "    # Concatena i dataframe in un unico dataframe\n",
    "    df = pd.concat(data_frames)\n",
    "\n",
    "    # Stampa il numero di righe del dataset\n",
    "    if verbose:\n",
    "        print(f\"Numero di record importati nel dataframe: {df.shape[0]}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = dataset_import(DATASET_PATH)\n",
    "\n",
    "if NSL_DATASET:\n",
    "    columns = (['duration','protocol_type','service','flag','src_bytes','dst_bytes','land','wrong_fragment','urgent','hot'\n",
    "    ,'num_failed_logins','logged_in','num_compromised','root_shell','su_attempted','num_root','num_file_creations'\n",
    "    ,'num_shells','num_access_files','num_outbound_cmds','is_host_login','is_guest_login','count','srv_count','serror_rate'\n",
    "    ,'srv_serror_rate','rerror_rate','srv_rerror_rate','same_srv_rate','diff_srv_rate','srv_diff_host_rate','dst_host_count','dst_host_srv_count'\n",
    "    ,'dst_host_same_srv_rate','dst_host_diff_srv_rate','dst_host_same_src_port_rate','dst_host_srv_diff_host_rate','dst_host_serror_rate'\n",
    "    ,'dst_host_srv_serror_rate','dst_host_rerror_rate','dst_host_srv_rerror_rate','attack','level'])\n",
    "    df.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset cleaning\n",
    "# --------------------------\n",
    "import numpy as np\n",
    "\n",
    "def data_cleaning(df, verbose=True):\n",
    "    \"\"\"\n",
    "    Pulisce il dataset rimuovendo le righe con valori nulli,\n",
    "    valori infiniti e duplicati.\n",
    "    \"\"\"\n",
    "\n",
    "    # Rimuovi lo spazio iniziale nel nome delle colonne\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    # Rimuovi le righe contenenti valori nulli\n",
    "    null_counts = df.isnull().sum()\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Rimosse {null_counts.sum()} righe con valori nulli\")\n",
    "\n",
    "    # Rimuovi le righe con valori infiniti nelle colonne float\n",
    "    float_cols = df.select_dtypes(include=[np.float64])\n",
    "    num_inf_rows = np.isinf(float_cols).any(axis=1).sum()\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Rimosse {num_inf_rows} righe con valori infiniti\")\n",
    "\n",
    "    # Rimuovi le righe duplicate\n",
    "    duplicate_count = df.duplicated().sum()\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Rimosse {duplicate_count} righe duplicate\")\n",
    "\n",
    "    # Resetta l\"indice del dataset\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = data_cleaning(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estrai le feature e la variabile target\n",
    "# --------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot(y, verbose=True):\n",
    "    \"\"\"\n",
    "    Visualizza la distribuzione delle classi target.\n",
    "    \"\"\"\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.countplot(x=y, hue=y, palette=\"Set1\", legend=False)\n",
    "    plt.title(\"Distribuzione della variabile target\")\n",
    "    plt.xlabel(\"Classe Target\")\n",
    "    plt.ylabel(\"Conteggio\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "    # Stampa la percentuale di ciascuna classe rispetto al totale\n",
    "    class_counts = y.value_counts()\n",
    "    class_ratios = class_counts / len(y)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Distribuzione delle classi target:\")\n",
    "        for class_name, class_ratio in class_ratios.items():\n",
    "            print(f\"{class_name}: {class_ratio*100:.2f}% ({class_counts[class_name]}/{len(y)})\")\n",
    "\n",
    "def extract_X_and_Y(df, mapping, y_label, verbose=True):\n",
    "    \"\"\"\n",
    "    Estrai la colonna target (y) dalle feature dal dataset (X).\n",
    "    \"\"\"\n",
    "\n",
    "    # Visualizza le categorie target e il numero di record per ciascuna\n",
    "    if verbose:\n",
    "        print(\"Conteggio dei record per ogni categoria target:\\n\")\n",
    "        print(df[y_label].value_counts())\n",
    "\n",
    "    # Estrai le training features\n",
    "    X = df.copy().drop(y_label, axis=1)\n",
    "\n",
    "    # Estrai la colonna target\n",
    "    y = df[y_label].copy()\n",
    "\n",
    "    # Raggruppa le classi target secondo la variabile mapping\n",
    "    def expand_mapping(mapping):\n",
    "        new_mapping = {}\n",
    "\n",
    "        for key, value in mapping.items():\n",
    "            if isinstance(value, list):\n",
    "                for item in value:\n",
    "                    new_mapping[item] = key\n",
    "            else:\n",
    "                new_mapping[key] = value\n",
    "\n",
    "        return new_mapping\n",
    "\n",
    "    y = y.map(expand_mapping(mapping)).fillna(\"Malicious\")\n",
    "    \n",
    "    # Visualizza le categorie target e il numero di record per ciascuna\n",
    "    if verbose:\n",
    "        print(\"\\n\\nConteggio dei record per ogni categoria target dopo la trasformazione:\\n\")\n",
    "        print(y.value_counts())\n",
    "\n",
    "        plot(y)\n",
    "        \n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "X, y = extract_X_and_Y(df, MAPPING, Y_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncoding\n",
    "# --------------------------\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def one_hot_encoding(X, y, verbose=True):\n",
    "    \"\"\"\n",
    "    Applica la codifica one-hot alle colonne di tipo object.\n",
    "    \"\"\"\n",
    "\n",
    "    cols_to_ohe = X.select_dtypes(\"object\").columns\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Colonne da codificare con one-hot encoding:\")\n",
    "        print(cols_to_ohe)\n",
    "\n",
    "    ohe = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "    num_cols = ohe.fit_transform(X[cols_to_ohe])\n",
    "    num_cols_names = ohe.get_feature_names_out(cols_to_ohe)\n",
    "    ohe_df = pd.DataFrame(num_cols, columns=num_cols_names)\n",
    "    X = pd.concat([X.drop(columns=cols_to_ohe), ohe_df], axis=1)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "X, y = one_hot_encoding(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersampling\n",
    "# --------------------------\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "def undersampling(X, y, verbose=True):\n",
    "    \"\"\"\n",
    "    Effettua l'undersampling delle classi target.\n",
    "    \"\"\"\n",
    "\n",
    "    X, y = RandomUnderSampler().fit_resample(X, y)\n",
    "\n",
    "    if verbose:\n",
    "        plot(y)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "if BINARY:\n",
    "    X, y = undersampling(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection con XGBoost\n",
    "# --------------------------\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "def dataset_training_split_with_validation(X, y, p_train, p_val, p_test, random_state=42, shuffle=True):\n",
    "    \"\"\"\n",
    "    Suddivide il dataframe X (delle feature) in X_train, X_val e X_test \n",
    "    e il dataframe Y (target) in y_train, y_val, y_test secondo le percentuali fornite.\n",
    "    \"\"\"\n",
    "\n",
    "    # La suddivisione iniziale tra train e test produce X_train e y_train\n",
    "    # Vengono creati anche X_temp e y_temp, che produrranno gli altri sottoinsiemi\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X,y,                \n",
    "                                                        stratify=y,\n",
    "                                                        test_size=(1.0 - p_train),\n",
    "                                                        random_state=random_state,\n",
    "                                                        shuffle=shuffle)\n",
    "    # Applicando la condizione stratify garantiamo una distribuzione omogenea delle feature nei target\n",
    "    \n",
    "    # Il parametro fraction descrive la dimensione rilevante della dimensione di test\n",
    "    fraction = p_test / (p_val + p_test)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp,y_temp,stratify=y_temp,\n",
    "                                                      test_size=fraction,\n",
    "                                                      random_state=random_state,\n",
    "                                                      shuffle=shuffle)\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "def get_feature_importances(original_data, clf_params, verbose=False):\n",
    "    \"\"\"\n",
    "    Calcola l\"importanza delle feature utilizzando un classificatore XGBoost addestrato su \n",
    "    dati di addestramento e di convalida.\n",
    "    \"\"\"\n",
    "\n",
    "    # Estrai i dati originali\n",
    "    X_train, X_val, _, y_train, y_val, _ = original_data\n",
    "    \n",
    "    # Crea un\"istanza del classificatore XGBoost\n",
    "    xgb_clf = XGBClassifier(**clf_params)\n",
    "\n",
    "    # Addestra il classificatore\n",
    "    xgb_clf.fit(X_train, LabelEncoder().fit_transform(y_train),\n",
    "                 eval_set=[(X_val, LabelEncoder().fit_transform(y_val))], verbose=False)\n",
    "    \n",
    "    # Ottieni l'importanza delle feature\n",
    "    feature_importances = xgb_clf.feature_importances_\n",
    "    \n",
    "    if verbose:\n",
    "        # Determina la lunghezza massima dei nomi delle feature\n",
    "        max_feature_name_length = max(len(name) for name in X_train.columns)\n",
    "        print(f\"{'Feature':<{max_feature_name_length}}\\tImportanza\")\n",
    "        for name, importance in zip(X_train.columns, \n",
    "                                    feature_importances):\n",
    "            print(f\"{name:<{max_feature_name_length}}\\t{importance*100:.2f}%\")             \n",
    "    \n",
    "    return feature_importances\n",
    "\n",
    "def select_features_by_threshold(X, y, threshold=0.01, verbose=True):\n",
    "    \"\"\"\n",
    "    Seleziona le caratteristiche dal dataset originale in base a una data soglia di importanza.\n",
    "    \"\"\"\n",
    "\n",
    "    # Inizializza parametri del classificatore\n",
    "    if y.value_counts().shape[0] > 2:\n",
    "        objective=\"multi:softprob\"\n",
    "        eval_metric=\"mlogloss\"\n",
    "    else:\n",
    "        objective=\"binary:logistic\"\n",
    "        eval_metric=\"logloss\"\n",
    "\n",
    "    clf_params = dict(\n",
    "        objective=objective,\n",
    "        n_estimators=50,\n",
    "        eval_metric=eval_metric,\n",
    "        max_depth=3,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=0.1,\n",
    "        early_stopping_rounds=10,\n",
    "        random_state=42)\n",
    "\n",
    "    # Split del dataset\n",
    "    splitted_dataset = dataset_training_split_with_validation(X,y,0.75,0.10,0.15,42,True)\n",
    "\n",
    "    # Estrai i dati\n",
    "    X_train, X_val, X_test, _, _, _ = splitted_dataset\n",
    "    \n",
    "    # Ottieni l\"importanza delle feature\n",
    "    feature_importances = get_feature_importances(splitted_dataset, clf_params)\n",
    "    \n",
    "    # Ottieni i nomi delle feature\n",
    "    feature_names = X_train.columns\n",
    "    \n",
    "    # Seleziona le feature in base alla soglia\n",
    "    selected_features = np.where(feature_importances > threshold)[0]\n",
    "    \n",
    "    # Crea una lista di tuple contenenti i nomi delle feature e le importanze\n",
    "    feature_tuples = [(name, importance) for name, importance in \n",
    "        zip(feature_names[selected_features], feature_importances[selected_features])]\n",
    "    \n",
    "    # Ordina le feature selezionate per importanza in ordine decrescente\n",
    "    sorted_feature_tuples = sorted(feature_tuples, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Estrai i nomi delle feature e le importanze ordinate\n",
    "    sorted_feature_names = [tup[0] for tup in sorted_feature_tuples]\n",
    "    sorted_feature_importances = [tup[1] for tup in sorted_feature_tuples]\n",
    "    \n",
    "    # Sottoseleziona i dati originali con le feature selezionate\n",
    "    X_train_selected = X_train.loc[:, sorted_feature_names]\n",
    "    X_val_selected   = X_val.loc[:, sorted_feature_names]\n",
    "    X_test_selected  = X_test.loc[:, sorted_feature_names]\n",
    "\n",
    "    # Stampa il numero di feature selezionate\n",
    "    print(f\"Il numero di feature selezionate è: {len(sorted_feature_names)}/{len(feature_names)}\",\"\\n\")\n",
    "\n",
    "    # Stampa i nomi delle feature selezionate e le importanze se printing è True\n",
    "    if verbose:\n",
    "        max_feature_name_length = max(len(name) for name in sorted_feature_names)\n",
    "        print(f\"{'Feature':<{max_feature_name_length}}\\tImportanza\\n\")\n",
    "        for name, importance in sorted_feature_tuples:\n",
    "            print(f\"{name:<{max_feature_name_length}}\\t{importance*100:.2f}%\")\n",
    "    \n",
    "    return sorted_feature_names\n",
    "\n",
    "\n",
    "if XGB:\n",
    "    # Seleziona le feature con una soglia di importanza del 1%\n",
    "    feature_names = select_features_by_threshold(X, y, threshold=0.01)\n",
    "    X = X[feature_names]\n",
    "else:\n",
    "    feature_names = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split del dataset\n",
    "# --------------------------\n",
    "training_split = train_test_split(X, y, test_size=0.33, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizzazione delle feature\n",
    "# --------------------------\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def standardize_features(training_split):\n",
    "    \"\"\"\n",
    "    Standardizza le feature del dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    # Creating Object\n",
    "    scaler = StandardScaler()\n",
    "    # Standardizing the features\n",
    "    training_split[0] = scaler.fit_transform(training_split[0])  \n",
    "    training_split[1] = scaler.transform(training_split[1])\n",
    "\n",
    "\n",
    "standardize_features(training_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "# --------------------------\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "def accuracy_report(y_test, y_pred):\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.10f}\")\n",
    "\n",
    "    # Print confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "    # Print classification report\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    print(\"Classification Report:\")\n",
    "    print(class_report)\n",
    "\n",
    "def feature_report(features, importances):\n",
    "    importance_df = pd.DataFrame({\"Feature\": features, \"Importance\": importances})\\\n",
    "        .sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "    # Stampa le feature più importanti\n",
    "    print(\"\\nFeature più importanti:\")\n",
    "    print(importance_df.head(10))\n",
    "\n",
    "def plot_confusion_matrix(model, y_test, y_pred):\n",
    "    \"\"\"\n",
    "    Visualizza la matrice di confusione del modello.\n",
    "    \"\"\"\n",
    "    # Calcola la matrice di confusione\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "    plt.title(\"Matrice di confusione\")\n",
    "    plt.xlabel(\"Etichette Predette\")\n",
    "    plt.ylabel(\"Etichette Vere\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc_curve(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Visualizza la curva ROC del modello.\n",
    "    \"\"\"\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calcola la ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba, pos_label=\"Malicious\") \n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Disegna la ROC curve\n",
    "    plt.figure()  \n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def train(models, training_split, feature_names):\n",
    "    X_train, X_test, y_train, y_test = training_split\n",
    "\n",
    "    for model in models:\n",
    "        print(f\"\\n\\nTraining con modello: {model.__class__.__name__}\")\n",
    "        print(\"--------------------------------------------------\")\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        accuracy_report(y_test, y_pred)\n",
    "\n",
    "        if hasattr(model, \"feature_importances_\"):\n",
    "            feature_report(feature_names, model.feature_importances_)\n",
    "\n",
    "        # Visualizza la matrice di confusione\n",
    "        plot_confusion_matrix(model, y_test, y_pred)\n",
    "\n",
    "        # Visualizza la curva ROC\n",
    "        plot_roc_curve(model, X_test, y_test)\n",
    "\n",
    "def train_k_fold(models, kfold, training_data):\n",
    "    X, y = training_data\n",
    "\n",
    "    scoring = [\"accuracy\", \"precision_weighted\", \"recall_weighted\", \"f1_weighted\"]\n",
    "\n",
    "    for model in models:\n",
    "        print(f\"\\n\\nTraining con modello: {model.__class__.__name__}\")\n",
    "        print(\"--------------------------------------------------\")\n",
    "    \n",
    "        scores = cross_validate(model, X, y, cv=kfold, scoring=scoring)\n",
    "\n",
    "        # Stampa un report sulle metriche di valutazione del modello\n",
    "        print(f\"Media delle metriche di valutazione dopo {kfold}-fold cross validation:\")\n",
    "\n",
    "        indexes = list(scores.keys())\n",
    "\n",
    "        for index in indexes:\n",
    "            print(f\"\\t{index}: %0.2f (+/- %0.2f)\" % (scores[index].mean(), scores[index].std() * 2))\n",
    "\n",
    "def train_k_fold_strat(models, skf, training_data):\n",
    "    X, y = training_data\n",
    "    target_names = np.unique(y)\n",
    "\n",
    "    for model in models:\n",
    "        print(f\"\\n\\nTraining con modello: {model.__class__.__name__}\")\n",
    "        print(\"--------------------------------------------------\")\n",
    "    \n",
    "        # Perform stratified k-fold cross-validation and collect results\n",
    "        reports = []\n",
    "\n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            \n",
    "            # Initialize and train the model\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Make predictions and evaluate the model\n",
    "            y_pred = model.predict(X_test)\n",
    "            report = classification_report(y_test, y_pred, target_names=target_names, output_dict=True)\n",
    "            reports.append(report)\n",
    "\n",
    "        # Initialize a dictionary to store average metrics\n",
    "        avg_report = {label: {\"precision\": 0, \"recall\": 0, \"f1-score\": 0, \"support\": 0} for label in target_names}\n",
    "        avg_report[\"accuracy\"] = 0\n",
    "\n",
    "        # Aggregate metrics\n",
    "        for report in reports:\n",
    "            for label in target_names:\n",
    "                avg_report[label][\"precision\"] += report[label][\"precision\"]\n",
    "                avg_report[label][\"recall\"] += report[label][\"recall\"]\n",
    "                avg_report[label][\"f1-score\"] += report[label][\"f1-score\"]\n",
    "                avg_report[label][\"support\"] += report[label][\"support\"]\n",
    "            avg_report[\"accuracy\"] += report[\"accuracy\"]\n",
    "\n",
    "        # Average the metrics\n",
    "        num_folds = skf.get_n_splits()\n",
    "        for label in target_names:\n",
    "            avg_report[label][\"precision\"] /= num_folds\n",
    "            avg_report[label][\"recall\"] /= num_folds\n",
    "            avg_report[label][\"f1-score\"] /= num_folds\n",
    "            avg_report[label][\"support\"] /= num_folds\n",
    "        avg_report[\"accuracy\"] /= num_folds\n",
    "\n",
    "        # Print the average report\n",
    "        print(\"Report finale dopo la cross-validation stratificata:\")\n",
    "        for label in target_names:\n",
    "            print(f\"Class: {label}\")\n",
    "            print(f\"  Precision: {avg_report[label]['precision']:.4f}\")\n",
    "            print(f\"  Recall: {avg_report[label]['recall']:.4f}\")\n",
    "            print(f\"  F1-Score: {avg_report[label]['f1-score']:.4f}\")\n",
    "            print(f\"  Support: {avg_report[label]['support']:.2f}\\n\")\n",
    "        print(f\"Overall Accuracy: {avg_report['accuracy']:.4f}\")\n",
    "\n",
    "\n",
    "if KFOLD_TRAINING:\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    train_k_fold(models, kfold, [X, y])\n",
    "\n",
    "if KFOLDSTRAT_TRAINING:\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    train_k_fold_strat(models, skf, [X, y])\n",
    "\n",
    "if BINARY and not(GRID_SEARCH):\n",
    "    train(models, training_split, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def grid_search(training_split, param_grid, verbose=True):\n",
    "    \"\"\"\n",
    "    Esegue una grid search per trovare i migliori parametri per la rete neurale \n",
    "    e stampa la performance e il tempo per ogni combinazione.\n",
    "    \"\"\"\n",
    "\n",
    "    # Inizializza la rete neurale\n",
    "    model = MLPClassifier(random_state=42, verbose=False)\n",
    "\n",
    "    # Crea l'oggetto GridSearchCV\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, return_train_score=True)\n",
    "\n",
    "    # Ottieni i dati di addestramento\n",
    "    X_train, _, y_train, _ = training_split\n",
    "\n",
    "    # Misura il tempo di inizio\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Allena il modello con i parametri della grid search\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Misura il tempo di fine\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calcola il tempo totale impiegato per la grid search\n",
    "    total_time = end_time - start_time\n",
    "\n",
    "    # Ottieni i risultati completi della grid search\n",
    "    results = grid_search.cv_results_\n",
    "\n",
    "    # Stampa i risultati per ogni combinazione di parametri\n",
    "    if verbose:\n",
    "        print(f\"{'Params':<60} {'Mean Test Score':<20} {'Fit Time (s)':<15}\")\n",
    "        print(\"=\" * 100)\n",
    "        for mean_score, params, fit_time in zip(results['mean_test_score'], results['params'], results['mean_fit_time']):\n",
    "            print(f\"{str(params):<60} {mean_score:<20.4f} {fit_time:<15.4f}\")\n",
    "\n",
    "    # Ottieni i migliori parametri e il miglior punteggio\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    # Stampa i migliori parametri e il miglior punteggio\n",
    "    if verbose:\n",
    "        print(\"\\nBest Parameters:\", best_params)\n",
    "        print(\"Best Score:\", best_score)\n",
    "        print(\"Total Time for Grid Search: {:.2f} seconds\".format(total_time))\n",
    "\n",
    "    return best_params, best_score\n",
    "\n",
    "\n",
    "if GRID_SEARCH:\n",
    "    grid_search(training_split, PARAM_GRID)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
